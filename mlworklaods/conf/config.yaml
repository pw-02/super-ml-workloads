
defaults:
  - _self_
  - dataloader: torch_lru #shade, torch_lru, super
  - dataset: openwebtext  #imagenet, cifar10, openwebtext
  - training: pythia160m #resnet18,resnet50, pythia14m, pythia160m
  - override hydra/job_logging: disabled
  - override hydra/hydra_logging: disabled  


num_devices_per_job: 1
seed: 42
accelerator: 'gpu'
log_interval: 1
log_dir: logs
checkpoint_interval: .inf
run_training: True
run_evaluation: False
num_workers_per_job: 2
exp_id: multi_job
job_id: 1

hydra:
  run:
    dir: .  # Current directory or a specific directory where Ray Tune expects to find it
  sweep:
    dir: .  # Same as above
  output_subdir: null
  job_logging:
    level: DISABLE  # Disable job-specific logging
  hydra_logging:
    level: DISABLE  # Disable Hydra-specific logging

# hydra:  
#   output_subdir: null  
#   run:  
#     dir: .

# hydra:
#   mode: MULTIRUN
#   output_subdir: null
#   sweeper:
#     params:
#       training: resnet18
#       # training: resnet50, shufflenet, vgg16

# Disable Hydra logging while ensuring Ray Tune can still manage its directories
