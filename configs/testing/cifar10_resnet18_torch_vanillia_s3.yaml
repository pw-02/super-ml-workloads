
workload:
    workers: 0
    accelerator: 'gpu'
    devices: 1
    epochs: 1
    max_minibatches_per_epoch: 50
    run_training: True
    run_evaluate: False
    save_checkpoints: False
    save_dir: models
    training_seed: 1

model:
    arch: resnet18
    weight_decay: 1.0e-4
    lr: 0.896
    momentum: 0.875
    optimizer: sgd
    grad_acc_steps: null

data:
    dataloader_backend: pytorch-vanillia #'super', 'pytorch-vanillia','pytorch-batched'
    train_data_dir: s3://sdl-cifar10/train/
    eval_data_dir: s3://sdl-cifar10/test/
    batch_size: 128
    shuffle: False
    sampler_seed: 1
    drop_last: False
    use_cache: False
    #the following are super cache specific
    cache_host: ip-10-0-31-114.us-west-2.compute.internal  #localhost
    cache_port: 6378 #6379

reporting:
    profile: True
    exp_name: cifar10
    flush_logs_every_n_steps: 1
    report_dir: reports
    print_freq: 1




